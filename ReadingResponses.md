## Reading Prompt

For each reading, pick two sentence/passages. One should be where the had an AHA! moment and one that is unclear, confusing, or needs further explanation. Provide a sentence or two explaining each of your selections.  Provide your response below.

 

### 2017-09-18: Distant reading
My moment of confusion came with Schulz's "What Is Distant Reading?" when she explains that although Moretti would like to treat literary analysis like a science, it doesn't work out perfectly because literature has been created by humans (and not by nature), so it does not abide by a consistent set of laws. How can we quantify data in literature if what "he perceives inside stories are as imposed as exposed"? Moretti even states in his work *Graphs, Maps, Trees* that "quantitative research provides a type of data which is ideally independent of interpretations," which Schulz argues is simply not true.

My AHA moment came when Moretti admitted that the history of literature (in this case the relationship between genres and generations) is not exact enough to make perfect predictions or analyses, conceding that "'generation' is itself a very questionable concept." Though this didn't necessarily provide more clarity, it did provide a necessary critique of the practice of distant reading and an explanation of the origin of the defining characteristics of generations.

### 2017-09-25: Topic modeling I
The part of Megan Brett's article that confused me the most is the size of the corpus needed for topic modeling. Why does MALLET need a minimum of 1000 works? What if I don't need such a large sample size?
However, her analogy of manual text-analysis with a highlighter helped me to understand the MALLET program as a way of identifying key concepts, but in a much more efficient manor than one person color-coding an article with highlighters.

The most confusing part of Wiengart and Meeks' article was their reference to "gray literature". I believe they are referring to nontraditional forms of literature like twitter threads and blog posts, but even then, how do those forms of "literature" apply to topic modeling?
My AHA moment came towards the end of the article when they admitted that topic modeling is "not an upgrade from simplistic human-driven research, but merely {another tool} in the ever-growing shed." This helped to solidify both the practicality and potential of these kinds of tools. 

With Underwood and Goldstone's discussion of the benefits and drawbacks of topic modeling, I began to wonder how one can clearly and efficiently map these groups of randomly associated words into topics useful for analysis. How can one tell what is a relevant connection and what is completely random without close reading such a large body of texts.
One of the more clear points in this article was the analogy of the puzzle. According to Underwood and Goldstone, the differences among topic modeling programs (or even every time you run the same program) are like the differences between a 100 piece puzzle and a 150 piece puzzle. Each individual piece will look different, but once each puzzle is completed, they form the same image.

Though Martha Ballard's diary presented a more concrete example of topic modeling, I am still confused as to how these groups of words can be analyzed effectively. With such a large body of work, it astonishes me that Blevins was able to glean something out of these topics, without actually reading every diary entry. 
I suppose Belvin's visuals were most helpful to me. By mapping these correlating groups of words (that I still don't quite understand), he was able to clearly present trends of each of these topics, making his point much more clear by properly labelling his graphs and providing adequate context. 

### 2017-10-02: Topic Modeling II

### 2017-10-09: Stylometry

### 2017-10-18: Spatial history

### 2017-10-23: Mapping: A Critical Introductin

### 2017-11-06: Social networks

### 2017-11-13: Layering Networks

### 2017-11-27: Critical DH
